# -*- coding: utf-8 -*-
"""OnlinePaymentsFraudDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mefY0rEjYozxlWwi6ezfRTJTSTybx7wv

# Online Payments Fraud Detection

In this project I will solve a classification problem on online fraud payments detection using machine learning. For this task, I collected a [dataset](https://www.kaggle.com/datasets/ealaxi/paysim1?resource=download) from Kaggle, which contains historical information about fraudulent transactions which can be used to detect fraud in online payments.

Below are all the columns from the dataset Iâ€™m using here:

- *step*: represents a unit of time where 1 step equals 1 hour
- *type*: type of online transaction
- *amount*: the amount of the transaction
- *nameOrig*: customer starting the transaction
- *oldbalanceOrg*: balance before the transaction
- *newbalanceOrig*: balance after the transaction
- *nameDest*: recipient of the transaction
- *oldbalanceDest*: initial balance of recipient before the transaction
- *newbalanceDest*: the new balance of recipient after the transaction
- *isFraud*: fraud transaction
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Importing necessary libraries and dataset




"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from plotly.offline import init_notebook_mode, plot, iplot
import cufflinks as cf
init_notebook_mode(connected=True)
cf.go_offline()
import plotly.express as px
import plotly.io as pio
pio.renderers.default = "colab"
pio.templates.default = 'seaborn'

df = pd.read_csv('/content/onlinefraud.csv')

"""### Dataset Cleaning and Evaluation"""

df.info()

df.head(15)

df.describe()

df.isFraud.value_counts()

df.isFlaggedFraud.value_counts()

merged_df = pd.merge(df[df['isFraud']==1], df[df['isFlaggedFraud']==1], how='outer', indicator=True)
common_rows = merged_df[merged_df['_merge'] == 'both']

len(common_rows)

df.isnull().sum()

"""No null values present in the dataset. No cleaning
of the dataset needed.

### EDA
"""

# Correlation between isFraud feature with other features
# df.corr(numeric_only=True)['isFraud'].sort_values(ascending=False)[1:].iplot(kind='bar')
fig1 = px.bar(x=df.corr(numeric_only=True)['isFraud'].sort_values(ascending=False)[1:].index, y=df.corr(numeric_only=True)['isFraud'].sort_values(ascending=False)[1:].values,
              color=df.corr(numeric_only=True)['isFraud'].sort_values(ascending=False)[1:].index, color_discrete_sequence=px.colors.sequential.Viridis_r,
              text=df.corr(numeric_only=True)['isFraud'].sort_values(ascending=False)[1:].values, title='Target Feature (isFraud) Correlation Plot')
fig1.update_xaxes(title_text='Features')
fig1.update_yaxes(title_text='Correlation')

"""The correlation plot shows that isFraud feature is most correlated with the amount of transaction made, though it is only 7.6%. isFraud feature is negatively correlated with oldbalanceDest and newbalanceOrig features."""

df.type.value_counts().sort_values()

# Transaction Type Distribution
fig2 = px.pie(data_frame=df,
              values=df.type.value_counts().sort_values().values,
              names=df.type.value_counts().sort_values().index,
              title='Distribution of Transaction Type', color=df.type.value_counts().sort_values().index,
             color_discrete_sequence=px.colors.sequential.Viridis_r, height=500)
fig2

"""The above transaction type distribution shows that CASH_OUT, PAYMENT and CASH_IN are top 3 most preferred transaction types with TRANSFER and DEBIT being the least preferred.

### Tailoring dataset
"""

df['type'] = df['type'].map({'CASH_OUT':1, 'PAYMENT':2, 'CASH_IN': 3, 'TRANSFER': 4, 'DEBIT': 5})
df['isFraud'] = df['isFraud'].map({0: 'No Fraud', 1: 'Fraud'})
# df['isFlaggedFraud'] = df['isFlaggedFraud'].map({0: 'No Fraud', 1: 'Fraud'})
df.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)

df.head()

from sklearn.model_selection import train_test_split

"""As the dataset is quite large and it may take very long to train model on such a large dataset. So I will use only a small portion of the dataset to continue with this project."""

current_ratio = df.isFraud.value_counts(normalize=True)
current_ratio

new_df_size = 80000
nofraud_need, fraud_need = np.ceil(new_df_size*current_ratio).astype(int)

df_nofraud = df[df['isFraud'] == 'No Fraud'].sample(nofraud_need)
df_fraud = df[df['isFraud'] == 'Fraud'].sample(fraud_need)
df_new = pd.concat([df_nofraud, df_fraud], ignore_index=True)
df_new.head()

X_new = df_new.drop('isFraud', axis=1)
y_new = df_new.isFraud

# X = df.drop('isFraud', axis=1).iloc[:80000]
# y = df.isFraud.iloc[:80000]

y_new.value_counts()

X_train, X_out, y_train, y_out = train_test_split(X_new, y_new, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_out, y_out, test_size=0.5, random_state=42)

"""### Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier()
from sklearn.model_selection import GridSearchCV
param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],
              'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],
              'max_features': [2, 3, 8, 'sqrt', 'log2']
              }
from sklearn.metrics import f1_score, make_scorer

# Define a custom scorer
f1_scorer = make_scorer(f1_score, pos_label='Fraud')
# from sklearn.metrics import SCORERS
# print(SCORERS.keys())
dtree_grid = GridSearchCV(estimator=dtree,
                          param_grid=param_grid,
                          n_jobs=-1,
                          cv=5,
                          scoring=f1_scorer,
                          error_score="raise"
                          )

dtree_grid.fit(X_train, y_train)

dtree_grid.best_estimator_

dtree_grid.best_params_

dtree_grid.best_score_

dtree_pred = dtree_grid.predict(X_val)
from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score

precision, recall, thresholds = precision_recall_curve(y_val, dtree_grid.best_estimator_.predict_proba(X_val)[:, 0], pos_label='Fraud')
# find threshold closest to zero
close_zero = np.argmin(np.abs(thresholds))
plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10, label="threshold zero", fillstyle="none", c='k', mew=2)
plt.plot(precision, recall, label="precision recall curve")
plt.title('Precision Recall Curve: DecisionTreeClassifier')
plt.xlabel("Precision")
plt.ylabel("Recall")
plt.legend(loc='best')

fpr, tpr, thresholds = roc_curve(y_val, dtree_grid.best_estimator_.predict_proba(X_val)[:, 0], pos_label='Fraud')
plt.title('ROC Curve: DecisionTreeClassifier')
plt.plot(fpr, tpr, label="ROC Curve")
plt.xlabel("FPR")
plt.ylabel("TPR (recall)")
# find threshold closest to zero
close_zero = np.argmin(np.abs(thresholds))
plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10, label="threshold zero", fillstyle="none", c='k', mew=2)
plt.legend(loc=4)

print('AUC of Decision Tree: ', roc_auc_score(y_val, dtree_grid.best_estimator_.predict_proba(X_val)[:, 1]))

print('Decision Tree Classifier: Confusion Matrix')
ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_val, dtree_pred), display_labels=dtree_grid.classes_).plot();

print(f"Classification Report Decision Tree Classifier:\n{classification_report(y_val, dtree_pred)}")

"""### Final Test Set Evaluation"""

test_pred = dtree_grid.predict(X_test)

print('Decision Tree Classifier: Test Set Confusion Matrix')
ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, test_pred), display_labels=dtree_grid.classes_).plot();

print(f"Classification Report Decision Tree Classifier Test Set:\n{classification_report(y_test, test_pred)}")

feature_names = ['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFlaggedFraud']
features = np.array([[1, 1, 100000.0, 100000.0, 0.0, 0.0, 0.0, 0]])
features_df = pd.DataFrame(features, columns=feature_names)
print(dtree_grid.predict(features_df))

"""### Conclusion
So the decision tree classifier performs well on the final test set correctly classifying most of the fraud payments. It also correctly classified the features_df.
"""